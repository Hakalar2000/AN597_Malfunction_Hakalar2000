---
title: "Malfunction"
author: "Me"
date: "October 19, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
*Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); 
*p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; 
*p0 (no default) as the expected value for the population proportion; 
*alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().
*When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
*The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
*The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5 to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
*The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
#so I don't really understand the underlying stuff we need to write the function so lets solve this problem without the function first. 

#Let us make fake data (marbles in a bag labeled 1 through 100 with replacement)
v <- c(0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 
    1, 1, 0, 1, 0, 1, 1) #fake vector data
m<-mean(v)
m
#one sample test scenario: previous data suggests there should be 80% successes
p<-0.8
n<-length(v)
n
pt <- prop.test(x = sum(v), n = length(v), p = 0.8, conf.level = 0.95, correct = FALSE, 
    alternative = "less") #1 line lower tail test that provides CIs
pt
n * p #greater than 5
n*(1-p) #greater than 5

#ok so far I understand that p is the expected proportion of an event and n is again the length of the sample data. 

#two sample test
v1 <- c(1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 
    1, 0)
p1<-sum(v1>=1)/length(v1) 
p1 #proportion of success for v1
n1<-length(v1)
v2 <- c(1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 
    0, 1, 1, 0, 1, 1, 1)
p2<-sum(v2>=1)/length(v1) 
p2
n2<-length(v2)

pt <- prop.test(x = c(sum(v2), sum(v1)), n = c(length(v2), length(v1)), alternative = "two.sided", 
    correct = FALSE)
pt #the same except for alternative is different.
n1*p1
n1*(1-p1)

n2*p2
n2*(1-p2) #this doesn't actually work.... so we need to code an error message for this.

#now we write our function so the journey begins
#I know the basic structure of a function:
name<-function(argument){
  Statement
}
#Now I need to add in a bunch of statement stuff so I can use it on any proportional data set. 
#Look at functions we have already used. Like lets look at Anova by going online. Probably need to use if statement. If someone chooses this option, then the function will do this. 

z.prop.test<-function(x, y, p){
  if(missing(y)) {
        x
    n1<-length(x)
    z<-prop.test(x = sum(x), n = n1, p, conf.level = 0.95, correct = FALSE, alternative = "less")
    p1<-sum(x>=1)/length(x)
    if(n1 * p1 < 5 || n1*(1-p1) < 5){
      print("Warning: your parameters are fucked")
      }
    } else {
    n1<- length(x)
    n2<- length(y)
    p1<-sum(x>=1)/length(x)
    p2<-sum(y>=1)/length(y)
    z<-prop.test(x = c(sum(x), sum(y)), n = c(n1, n2), alternative = "two.sided", 
    correct = FALSE)
    if(n1 * p1 < 5 || n1*(1-p1) < 5 || n2 * p2 < 5 || n2*(1-p2)<5){
      print("Warning: your parameters are fucked")
      }
  }
}

x <- c(1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 
    1, 0)
y <- c(1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 
    0, 1, 1, 0, 1, 1, 1)

#I got no idea why this error keeps popping up...

a<-z.prop.test(x, y, p = 0.8)
a

#It ain't working...

#lets try again:

test<-function(x, y) {
  n1<-length(x)
  n2<-length(y)
  p1<-sum(x>=1)/n1
  p2<-sum(y>=1)/n2
  if (n1 * p1 > 5 || n1*(1-p1) > 5 || n2 * p2 > 5 || n2 * 1-p2 > 5){
      print("Warning: your parameters are fucked")
      } else {
      print("hey, you did something")
    }
}

test(x, y)

```


2. The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):
#Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
#Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.
#Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.
#Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
#Looking at your two models, which do you think is better? Why?


```{r}
#First lets load out packages that we will need:
library(curl)
library(ggplot2)
install.packages("ggpmisc")
library(ggpmisc) #for adding equations to my graph
library(gridExtra)
```

```{r}
#Next load in data:
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall19/KamilarAndCooperData.csv")
t <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
why<-na.omit(t) #gotta get rid of NA values
d<-data.frame(why) #gotta put our data into a data.frame to work with ggplot
x<-d$MaxLongevity_m #time variable is going to be x
y<-d$Brain_Size_Species_Mean #dependent variable is y
r<-cbind(x, y) #I will need this later on when combining dataframes. 
```

Lets start with our regular regression
```{r}
#Now we can work out the problem 

#with the lm() function, we can calculate  Model I and plot regression

Mod<-lm(data = d, y~x) #not hard, but note that the lm() function yeilds the OSL regression and there are other types we could have tried but were to lazy to do. 
Mod
summary(Mod)

#Ok regression coefficients beta1 and beta0
  #x is life
  #y is size
beta1 <- cor(x, y) * (sd(x)/sd(y))
beta1
beta0 <- mean(x) - beta1 * mean(y)
beta0
ci.slope<-confint(Mod, level = 0.9)
ci.slope #x parameter of the output gives you the upper and lower CIs. 
#please note that a CI of 90% corresponds to values between the lower 5% and upper 95%. 

#Now we use ggplot and the package we pulled from le internet to do the do

gMod1<-ggplot(data = d, aes(x = x, y = y)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + stat_poly_eq(formula = Mod, aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), parse = TRUE)
gMod1
#I have no idea why it comes out with a parabolic equation...

Mod
summary(Mod)
ci <- predict(Mod, newdata = data.frame(size = d$Brain_Size_Species_Mean), interval = "confidence", 
    level = 0.90)  # CIs for a vector of values
head(ci)
ci.frame<-data.frame(ci) #had to change these to dataframe to combine them later on
pi <- predict(Mod, newdata = data.frame(size = d$Brain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  # for a vector of values
head(pi)
pi.frame<-data.frame(pi)
New<-cbind(r, ci.frame, pi.frame)
names(New) <- c("x", "y", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") #renaming columns
head(New)

gModII<-ggplot(data = New, aes(x = x, y = y)) + geom_point() + 
  geom_line(data = New, aes(x = x, y = CIfit), colour = "black") +
  geom_line(data = New, aes(x = x, y = CIlwr), colour = "blue") +
  geom_line(data = New, aes(x = x, y = CIupr), colour = "blue") +
  geom_line(data = New, aes(x = x, y = PIlwr), colour = "red") +
  geom_line(data = New, aes(x = x, y = PIupr), colour = "red")
gModII

#To whomever has to give me commentary. Idk why, but when I first ran my code, my CIs and PIs were not working at all for some reason and then they magically decided to now work...Idk man...its magic. 


```
Now lets do our log transformed regression
```{r}
logMod<-lm(data = d, log(y)~log(x))
logMod
summary(logMod)
ci.slope.log<-confint(logMod, level = 0.9)
ci.slope.log
glogModI<-ggplot(data = d, aes(x = log(x), y = log(y))) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + stat_poly_eq(formula = logMod, aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), parse = TRUE)
glogModI
summary(logMod)
ci <- predict(logMod, newdata = data.frame(size = d$Brain_Size_Species_Mean), interval = "confidence", 
    level = 0.90)  # CIs for a vector of values
head(ci)
logci.frame<-data.frame(ci)
pi <- predict(logMod, newdata = data.frame(size = d$Brain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  # for a vector of values
head(pi)
logpi.frame<-data.frame(pi)
logNew<-cbind(r, logci.frame, logpi.frame)
names(logNew) <- c("x", "y", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") #renaming columns
head(logNew)
glogModII<-ggplot(data = d, aes(x = log(x), y = log(y))) + geom_point() + geom_line(data = logNew, aes(x = log(x), y = CIfit), colour = "black") + geom_line(data = logNew, aes(x = log(x), y = CIlwr), colour = "blue") + geom_line(data = logNew, aes(x = log(x), y = CIupr), colour = "blue") + geom_line(data = logNew, aes(x = log(x), y = PIlwr), colour = "red") + geom_line(data = logNew, aes(x = log(x), y = PIupr), colour = "red")
glogModII
```
point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm
```{r}
Mod <- lm(data = n, x ~ y)
summary(Mod)
pi <- predict(Mod, newdata = data.frame(y = 800), interval = "prediction", 
    level = 0.90)  # for a single value
pi
#Not sure why, but I had to switch x and y on my regression model for the predict function to actually give me an estimate for a single specified value...odd. 
#I'd say this is not the greatest prediction cause there is a lot of psace between the CIs. 
```
Honestly I think my original model was better than my log transformed model. My p values are lower and my R squared values are higher suggesting that my original model is more concise. The points are spread closer to the models fit. Also in terms of the hypotheses, the slope of both models is definietly not 0 = HA accepted. 


Five things that emotionally killed me inside:
*How do you write a function...help
*I'm not sure what was meant by interpret the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0...I'm sure this one is simple
*I'm an egotistical bitch and I think I'm a legend, but I can't fucking figure out how to add a legend to my goddam ggplot. Like why is this the most difficult ggplot thing to do?
*"Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?" um is this a p value thing cuase its got a lot of wiggle room according to the CIs. 



